{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize (Convert to lowercase):\n",
    "       text = text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural language processing with python!\n"
     ]
    }
   ],
   "source": [
    "text = \"Natural Language Processing with Python!\"\n",
    "text = text.lower()\n",
    "print(text)  # Output: \"natural language processing with python!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unwanted characters (punctuation, numbers, emojis, dates): \n",
    "use regular expressions (re) to remove punctuation, numbers, emojis, and dates:\n",
    "\n",
    "\n",
    "    import re\n",
    "\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # removes punctuation\n",
    "    text = re.sub(r'\\d+', '', text)      # removes numbers\n",
    "\n",
    "    # Optionally remove emojis (Unicode range)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        u\"\\U0001F780-\\U0001F7FF\"  # geometric shapes\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove dates (simple example)\n",
    "    text = re.sub(r'\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b', '', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World Today is  Lets meet at  PM \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello World! Today is 29/09/2024. Let's meet at 5:00 PM ðŸ˜Š.\"\n",
    "# Remove punctuation\n",
    "text = re.sub(r'[^\\w\\s]', '', text)  # \"Hello World Today is 29092024 Lets meet at 500 PM ðŸ˜Š\"\n",
    "# Remove numbers\n",
    "text = re.sub(r'\\d+', '', text)  # \"Hello World Today is Lets meet at PM ðŸ˜Š\"\n",
    "# Remove emojis\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "text = emoji_pattern.sub(r'', text)  # \"Hello World Today is Lets meet at PM \"\n",
    "print(text)  # Output: \"Hello World Today is Lets meet at PM \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove line breaks:\n",
    "\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World! This is a test.Let's remove line breaks.\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, World!\\nThis is a test.\\rLet's remove line breaks.\"\n",
    "text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words (using NLTK library): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords corpus if not done before\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "text = ' '.join([word for word in text.split() if word not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple example remove stop words.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Remove stop words\n",
    "cleaned_text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "print(cleaned_text)  # Output: \"simple example remove stop words.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use regular expressions for replacing unwanted data:\n",
    "To replace specific patterns with white space or specific initials:\n",
    "\n",
    "    text = re.sub(r'unwanted_pattern', 'replacement_text', text)\n",
    "\n",
    "For example, to replace URLs:\n",
    "\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Use regular expressions for replacing unwanted data\n",
    "You can replace unwanted patterns like URLs, special terms, or any specific pattern using regular expressions.\n",
    "\n",
    "Example: Replace URLs with an empty string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit our website at  for more details.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Visit our website at https://example.com for more details.\"\n",
    "text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "print(text)  # Output: \"Visit our website at  for more details.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We met on [DATE] for the event.\n"
     ]
    }
   ],
   "source": [
    "# Another Example: Replace dates with a placeholder:\n",
    "\n",
    "text = \"We met on 12/12/2023 for the event.\"\n",
    "text = re.sub(r'\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b', '[DATE]', text)\n",
    "print(text)  # Output: \"We met on [DATE] for the event.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove HTML tags from a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!This is a bold paragraph.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html_content = \"<html><body><h1>Hello, World!</h1><p>This is a <b>bold</b> paragraph.</p></body></html>\"\n",
    "# Parse the HTML\n",
    "soup=BeautifulSoup(html_content,'html.parser')\n",
    "# Extract text without tags\n",
    "txt=soup.getText()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!This is a bold paragraph.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html_content = \"<html><body><h1>Hello, World!</h1><p>This is a <b>bold</b> paragraph.</p></body></html>\"\n",
    "# Parse the HTML\n",
    "soup=BeautifulSoup(html_content,'html.parser')\n",
    "# Extract text without tags\n",
    "txt=soup.get_text()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
