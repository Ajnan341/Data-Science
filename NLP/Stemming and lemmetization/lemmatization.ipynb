{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context to the words. So, it links words with similar meanings to one word. \n",
    "Text preprocessing includes both Stemming as well as lemmatization. Many times, people find these two terms confusing. Some treat these two as the same. Lemmatization is preferred over Stemming because lemmatization does morphological analysis of the words.\n",
    "Examples of lemmatization:\n",
    "\n",
    "\n",
    "-> rocks : rock\n",
    "\n",
    "\n",
    "-> corpora : corpus\n",
    "\n",
    "\n",
    "-> better : good\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Rule Based Lemmatization\n",
    "Rule-based lemmatization involves the application of predefined rules to derive the base or root form of a word. Unlike machine learning-based approaches, which learn from data, rule-based lemmatization relies on linguistic rules and patterns.\n",
    "\n",
    "Here’s a simplified example of rule-based lemmatization for English verbs:\n",
    "\n",
    "Rule: For regular verbs ending in “-ed,” remove the “-ed” suffix.\n",
    "\n",
    "Example:\n",
    "\n",
    "Word: “walked”\n",
    "\n",
    "Rule Application: Remove “-ed”\n",
    "\n",
    "Result: “walk\n",
    "\n",
    "# 2. Dictionary-Based Lemmatization\n",
    "Dictionary-based lemmatization relies on predefined dictionaries or lookup tables to map words to their corresponding base forms or lemmas. Each word is matched against the dictionary entries to find its lemma. This method is effective for languages with well-defined rules.\n",
    "\n",
    "Suppose we have a dictionary with lemmatized forms for some words:\n",
    "\n",
    "‘running’ -> ‘run’\n",
    "\n",
    "‘better’ -> ‘good’\n",
    "\n",
    "‘went’ -> ‘go’\n",
    "\n",
    "When we apply dictionary-based lemmatization to a text like “I was running to become a better athlete, and then I went home,” the resulting lemmatized form would be: “I was run to become a good athlete, and then I go home.”\n",
    "\n",
    "\n",
    "# 3. Machine Learning-Based Lemmatization\n",
    "Machine learning-based lemmatization leverages computational models to automatically learn the relationships between words and their base forms. Unlike rule-based or dictionary-based approaches, machine learning models, such as neural networks or statistical models, are trained on large text datasets to generalize patterns in language.\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider a machine learning-based lemmatizer trained on diverse texts. When encountering the word ‘went,’ the model, having learned patterns, predicts the base form as ‘go.’ Similarly, for ‘happier,’ the model deduces ‘happy’ as the lemma. The advantage lies in the model’s ability to adapt to varied linguistic nuances and handle irregularities, making it robust for lemmatizing diverse vocabularies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Lemmatization\n",
    "# 1. NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks----->rock\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lm= WordNetLemmatizer()\n",
    "\n",
    "print(f\"rocks----->{lm.lemmatize('rocks')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars----->car\n"
     ]
    }
   ],
   "source": [
    "print(f\"cars----->{lm.lemmatize('cars')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better : good\n"
     ]
    }
   ],
   "source": [
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lm.lemmatize(\"better\", pos=\"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The quick brown foxes are jumping over the lazy dogs.\n",
      "Lemmatized Text: the quick brown fox be jump over the lazy dog .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define a sample text\n",
    "text = \"The quick brown foxes are jumping over the lazy dogs.\"\n",
    "# Process the text using spaCy\n",
    "w=nlp(text)\n",
    "\n",
    "\n",
    "lem_tokens=[t.lemma_ for t in w ]\n",
    "# Join the lemmatized tokens into a sentence\n",
    "lemmatized_text = ' '.join(lem_tokens)\n",
    " \n",
    "# Print the original and lemmatized text\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Lemmatized Text:\", lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
