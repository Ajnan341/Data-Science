{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Porter’s Stemmer\n",
    " It is one of the most popular stemming methods proposed in 1980. It is based on the idea that the suffixes in the English language are made up of a combination of smaller and simpler suffixes. This stemmer is known for its speed and simplicity. The main applications of Porter Stemmer include data mining and Information retrieval. However, its applications are only limited to English words. Also, the group of stems is mapped on to the same stem and the output stem is not necessarily a meaningful word. The algorithms are fairly lengthy in nature and are known to be the oldest stemmer.\n",
    "\n",
    "Example: EED -> EE means “if the word has at least one vowel and consonant plus EED ending, change the ending to EE” as ‘agreed’ becomes ‘agree’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['running', 'jumps', 'happily', 'running', 'happily']\n",
      "['run', 'jump', 'happili', 'run', 'happili']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps=PorterStemmer()\n",
    "words = [\"running\", \"jumps\", \"happily\", \"running\", \"happily\"]\n",
    "\n",
    "stemmedwords=[ps.stem(w) for w in words]\n",
    "print(words)\n",
    "print(stemmedwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Snowball Stemmer\n",
    "The Snowball Stemmer, compared to the Porter Stemmer, is multi-lingual as it can handle non-English words. It supports various languages and is based on the ‘Snowball’ programming language, known for efficient processing of small strings.\n",
    "\n",
    "The Snowball stemmer is way more aggressive than Porter Stemmer and is also referred to as Porter2 Stemmer. Because of the improvements added when compared to the Porter Stemmer, the Snowball stemmer is having greater computational speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['running', 'jumps', 'happily', 'running', 'happily']\n",
      "['run', 'jump', 'happili', 'run', 'happili']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "ss=SnowballStemmer(language='english')\n",
    "\n",
    "words = [\"running\", \"jumps\", \"happily\", \"running\", \"happily\"]\n",
    "\n",
    "stemmedwords=[ss.stem(w) for w in words]\n",
    "print(words)\n",
    "print(stemmedwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lancaster Stemmer\n",
    "The Lancaster stemmers are more aggressive and dynamic compared to the other two stemmers. The stemmer is really faster, but the algorithm is really confusing when dealing with small words. But they are not as efficient as Snowball Stemmers. The Lancaster stemmers save the rules externally and basically uses an iterative algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['running', 'jumps', 'happily', 'running', 'happily']\n",
      "['run', 'jump', 'happy', 'run', 'happy']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "ls=LancasterStemmer()\n",
    "\n",
    "words = [\"running\", \"jumps\", \"happily\", \"running\", \"happily\"]\n",
    "\n",
    "stemmedwords=[ls.stem(w) for w in words]\n",
    "print(words)\n",
    "print(stemmedwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Regexp Stemmer\n",
    "The Regexp Stemmer, or Regular Expression Stemmer, is a stemming algorithm that utilizes regular expressions to identify and remove suffixes from words. It allows users to define custom rules for stemming by specifying patterns to match and remove.\n",
    "\n",
    "This method provides flexibility and control over the stemming process, making it suitable for specific applications where custom rule-based stemming is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: running\n",
      "Stemmed Word: runn\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "# Create a Regexp Stemmer with a custom rule\n",
    "custom_rule = r'ing$'\n",
    "regexp_stemmer = RegexpStemmer(custom_rule)\n",
    "\n",
    "# Apply the stemmer to a word\n",
    "word = 'running'\n",
    "stemmed_word = regexp_stemmer.stem(word)\n",
    "\n",
    "print(f'Original Word: {word}')\n",
    "print(f'Stemmed Word: {stemmed_word}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/introduction-to-pynlpl-streamlining-nlp-workflows-with-python/?ref=ml_lbp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
